{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "255f9b33-3812-4a73-a5f0-0c1e2e8ac9c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformers\n",
      "  Using cached transformers-4.53.1-py3-none-any.whl.metadata (40 kB)\n",
      "Collecting sentence-transformers\n",
      "  Using cached sentence_transformers-5.0.0-py3-none-any.whl.metadata (16 kB)\n",
      "Collecting openai\n",
      "  Using cached openai-1.93.1-py3-none-any.whl.metadata (29 kB)\n",
      "Collecting chromadb\n",
      "  Using cached chromadb-1.0.15-cp39-abi3-win_amd64.whl.metadata (7.1 kB)\n",
      "Collecting fastapi\n",
      "  Using cached fastapi-0.116.0-py3-none-any.whl.metadata (28 kB)\n",
      "Collecting uvicorn\n",
      "  Using cached uvicorn-0.35.0-py3-none-any.whl.metadata (6.5 kB)\n",
      "Requirement already satisfied: nest-asyncio in c:\\misogi\\week5\\day1\\rag_evaluation\\intent_classifier\\myenv\\lib\\site-packages (1.6.0)\n",
      "Collecting filelock (from transformers)\n",
      "  Using cached filelock-3.18.0-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting huggingface-hub<1.0,>=0.30.0 (from transformers)\n",
      "  Using cached huggingface_hub-0.33.2-py3-none-any.whl.metadata (14 kB)\n",
      "Collecting numpy>=1.17 (from transformers)\n",
      "  Using cached numpy-2.3.1-cp312-cp312-win_amd64.whl.metadata (60 kB)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\misogi\\week5\\day1\\rag_evaluation\\intent_classifier\\myenv\\lib\\site-packages (from transformers) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\misogi\\week5\\day1\\rag_evaluation\\intent_classifier\\myenv\\lib\\site-packages (from transformers) (6.0.2)\n",
      "Collecting regex!=2019.12.17 (from transformers)\n",
      "  Using cached regex-2024.11.6-cp312-cp312-win_amd64.whl.metadata (41 kB)\n",
      "Requirement already satisfied: requests in c:\\misogi\\week5\\day1\\rag_evaluation\\intent_classifier\\myenv\\lib\\site-packages (from transformers) (2.32.4)\n",
      "Collecting tokenizers<0.22,>=0.21 (from transformers)\n",
      "  Using cached tokenizers-0.21.2-cp39-abi3-win_amd64.whl.metadata (6.9 kB)\n",
      "Collecting safetensors>=0.4.3 (from transformers)\n",
      "  Using cached safetensors-0.5.3-cp38-abi3-win_amd64.whl.metadata (3.9 kB)\n",
      "Collecting tqdm>=4.27 (from transformers)\n",
      "  Using cached tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
      "Collecting torch>=1.11.0 (from sentence-transformers)\n",
      "  Using cached torch-2.7.1-cp312-cp312-win_amd64.whl.metadata (28 kB)\n",
      "Collecting scikit-learn (from sentence-transformers)\n",
      "  Using cached scikit_learn-1.7.0-cp312-cp312-win_amd64.whl.metadata (14 kB)\n",
      "Collecting scipy (from sentence-transformers)\n",
      "  Using cached scipy-1.16.0-cp312-cp312-win_amd64.whl.metadata (60 kB)\n",
      "Collecting Pillow (from sentence-transformers)\n",
      "  Using cached pillow-11.3.0-cp312-cp312-win_amd64.whl.metadata (9.2 kB)\n",
      "Requirement already satisfied: typing_extensions>=4.5.0 in c:\\misogi\\week5\\day1\\rag_evaluation\\intent_classifier\\myenv\\lib\\site-packages (from sentence-transformers) (4.14.1)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\misogi\\week5\\day1\\rag_evaluation\\intent_classifier\\myenv\\lib\\site-packages (from openai) (4.9.0)\n",
      "Collecting distro<2,>=1.7.0 (from openai)\n",
      "  Using cached distro-1.9.0-py3-none-any.whl.metadata (6.8 kB)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\misogi\\week5\\day1\\rag_evaluation\\intent_classifier\\myenv\\lib\\site-packages (from openai) (0.28.1)\n",
      "Collecting jiter<1,>=0.4.0 (from openai)\n",
      "  Using cached jiter-0.10.0-cp312-cp312-win_amd64.whl.metadata (5.3 kB)\n",
      "Collecting pydantic<3,>=1.9.0 (from openai)\n",
      "  Using cached pydantic-2.11.7-py3-none-any.whl.metadata (67 kB)\n",
      "Requirement already satisfied: sniffio in c:\\misogi\\week5\\day1\\rag_evaluation\\intent_classifier\\myenv\\lib\\site-packages (from openai) (1.3.1)\n",
      "Collecting build>=1.0.3 (from chromadb)\n",
      "  Using cached build-1.2.2.post1-py3-none-any.whl.metadata (6.5 kB)\n",
      "Collecting pybase64>=1.4.1 (from chromadb)\n",
      "  Using cached pybase64-1.4.1-cp312-cp312-win_amd64.whl.metadata (8.7 kB)\n",
      "Collecting posthog<6.0.0,>=2.4.0 (from chromadb)\n",
      "  Using cached posthog-5.4.0-py3-none-any.whl.metadata (5.7 kB)\n",
      "Collecting onnxruntime>=1.14.1 (from chromadb)\n",
      "  Using cached onnxruntime-1.22.0-cp312-cp312-win_amd64.whl.metadata (5.0 kB)\n",
      "Collecting opentelemetry-api>=1.2.0 (from chromadb)\n",
      "  Using cached opentelemetry_api-1.34.1-py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting opentelemetry-exporter-otlp-proto-grpc>=1.2.0 (from chromadb)\n",
      "  Using cached opentelemetry_exporter_otlp_proto_grpc-1.34.1-py3-none-any.whl.metadata (2.4 kB)\n",
      "Collecting opentelemetry-sdk>=1.2.0 (from chromadb)\n",
      "  Using cached opentelemetry_sdk-1.34.1-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting pypika>=0.48.9 (from chromadb)\n",
      "  Using cached pypika-0.48.9-py2.py3-none-any.whl\n",
      "Requirement already satisfied: overrides>=7.3.1 in c:\\misogi\\week5\\day1\\rag_evaluation\\intent_classifier\\myenv\\lib\\site-packages (from chromadb) (7.7.0)\n",
      "Collecting importlib-resources (from chromadb)\n",
      "  Using cached importlib_resources-6.5.2-py3-none-any.whl.metadata (3.9 kB)\n",
      "Collecting grpcio>=1.58.0 (from chromadb)\n",
      "  Using cached grpcio-1.73.1-cp312-cp312-win_amd64.whl.metadata (4.0 kB)\n",
      "Collecting bcrypt>=4.0.1 (from chromadb)\n",
      "  Using cached bcrypt-4.3.0-cp39-abi3-win_amd64.whl.metadata (10 kB)\n",
      "Collecting typer>=0.9.0 (from chromadb)\n",
      "  Using cached typer-0.16.0-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting kubernetes>=28.1.0 (from chromadb)\n",
      "  Using cached kubernetes-33.1.0-py2.py3-none-any.whl.metadata (1.7 kB)\n",
      "Collecting tenacity>=8.2.3 (from chromadb)\n",
      "  Using cached tenacity-9.1.2-py3-none-any.whl.metadata (1.2 kB)\n",
      "Collecting mmh3>=4.0.1 (from chromadb)\n",
      "  Using cached mmh3-5.1.0-cp312-cp312-win_amd64.whl.metadata (16 kB)\n",
      "Collecting orjson>=3.9.12 (from chromadb)\n",
      "  Using cached orjson-3.10.18-cp312-cp312-win_amd64.whl.metadata (43 kB)\n",
      "Collecting rich>=10.11.0 (from chromadb)\n",
      "  Using cached rich-14.0.0-py3-none-any.whl.metadata (18 kB)\n",
      "Requirement already satisfied: jsonschema>=4.19.0 in c:\\misogi\\week5\\day1\\rag_evaluation\\intent_classifier\\myenv\\lib\\site-packages (from chromadb) (4.24.0)\n",
      "Collecting starlette<0.47.0,>=0.40.0 (from fastapi)\n",
      "  Using cached starlette-0.46.2-py3-none-any.whl.metadata (6.2 kB)\n",
      "Collecting click>=7.0 (from uvicorn)\n",
      "  Using cached click-8.2.1-py3-none-any.whl.metadata (2.5 kB)\n",
      "Requirement already satisfied: h11>=0.8 in c:\\misogi\\week5\\day1\\rag_evaluation\\intent_classifier\\myenv\\lib\\site-packages (from uvicorn) (0.16.0)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\misogi\\week5\\day1\\rag_evaluation\\intent_classifier\\myenv\\lib\\site-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
      "Collecting pyproject_hooks (from build>=1.0.3->chromadb)\n",
      "  Using cached pyproject_hooks-1.2.0-py3-none-any.whl.metadata (1.3 kB)\n",
      "Requirement already satisfied: colorama in c:\\misogi\\week5\\day1\\rag_evaluation\\intent_classifier\\myenv\\lib\\site-packages (from build>=1.0.3->chromadb) (0.4.6)\n",
      "Requirement already satisfied: certifi in c:\\misogi\\week5\\day1\\rag_evaluation\\intent_classifier\\myenv\\lib\\site-packages (from httpx<1,>=0.23.0->openai) (2025.6.15)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\misogi\\week5\\day1\\rag_evaluation\\intent_classifier\\myenv\\lib\\site-packages (from httpx<1,>=0.23.0->openai) (1.0.9)\n",
      "Collecting fsspec>=2023.5.0 (from huggingface-hub<1.0,>=0.30.0->transformers)\n",
      "  Using cached fsspec-2025.5.1-py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: attrs>=22.2.0 in c:\\misogi\\week5\\day1\\rag_evaluation\\intent_classifier\\myenv\\lib\\site-packages (from jsonschema>=4.19.0->chromadb) (25.3.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in c:\\misogi\\week5\\day1\\rag_evaluation\\intent_classifier\\myenv\\lib\\site-packages (from jsonschema>=4.19.0->chromadb) (2025.4.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in c:\\misogi\\week5\\day1\\rag_evaluation\\intent_classifier\\myenv\\lib\\site-packages (from jsonschema>=4.19.0->chromadb) (0.36.2)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in c:\\misogi\\week5\\day1\\rag_evaluation\\intent_classifier\\myenv\\lib\\site-packages (from jsonschema>=4.19.0->chromadb) (0.26.0)\n",
      "Requirement already satisfied: six>=1.9.0 in c:\\misogi\\week5\\day1\\rag_evaluation\\intent_classifier\\myenv\\lib\\site-packages (from kubernetes>=28.1.0->chromadb) (1.17.0)\n",
      "Requirement already satisfied: python-dateutil>=2.5.3 in c:\\misogi\\week5\\day1\\rag_evaluation\\intent_classifier\\myenv\\lib\\site-packages (from kubernetes>=28.1.0->chromadb) (2.9.0.post0)\n",
      "Collecting google-auth>=1.0.1 (from kubernetes>=28.1.0->chromadb)\n",
      "  Using cached google_auth-2.40.3-py2.py3-none-any.whl.metadata (6.2 kB)\n",
      "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in c:\\misogi\\week5\\day1\\rag_evaluation\\intent_classifier\\myenv\\lib\\site-packages (from kubernetes>=28.1.0->chromadb) (1.8.0)\n",
      "Collecting requests-oauthlib (from kubernetes>=28.1.0->chromadb)\n",
      "  Using cached requests_oauthlib-2.0.0-py2.py3-none-any.whl.metadata (11 kB)\n",
      "Collecting oauthlib>=3.2.2 (from kubernetes>=28.1.0->chromadb)\n",
      "  Using cached oauthlib-3.3.1-py3-none-any.whl.metadata (7.9 kB)\n",
      "Requirement already satisfied: urllib3>=1.24.2 in c:\\misogi\\week5\\day1\\rag_evaluation\\intent_classifier\\myenv\\lib\\site-packages (from kubernetes>=28.1.0->chromadb) (2.5.0)\n",
      "Collecting durationpy>=0.7 (from kubernetes>=28.1.0->chromadb)\n",
      "  Using cached durationpy-0.10-py3-none-any.whl.metadata (340 bytes)\n",
      "Collecting coloredlogs (from onnxruntime>=1.14.1->chromadb)\n",
      "  Using cached coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\n",
      "Collecting flatbuffers (from onnxruntime>=1.14.1->chromadb)\n",
      "  Using cached flatbuffers-25.2.10-py2.py3-none-any.whl.metadata (875 bytes)\n",
      "Collecting protobuf (from onnxruntime>=1.14.1->chromadb)\n",
      "  Using cached protobuf-6.31.1-cp310-abi3-win_amd64.whl.metadata (593 bytes)\n",
      "Collecting sympy (from onnxruntime>=1.14.1->chromadb)\n",
      "  Using cached sympy-1.14.0-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting importlib-metadata<8.8.0,>=6.0 (from opentelemetry-api>=1.2.0->chromadb)\n",
      "  Using cached importlib_metadata-8.7.0-py3-none-any.whl.metadata (4.8 kB)\n",
      "Collecting googleapis-common-protos~=1.52 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb)\n",
      "  Using cached googleapis_common_protos-1.70.0-py3-none-any.whl.metadata (9.3 kB)\n",
      "Collecting opentelemetry-exporter-otlp-proto-common==1.34.1 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb)\n",
      "  Using cached opentelemetry_exporter_otlp_proto_common-1.34.1-py3-none-any.whl.metadata (1.9 kB)\n",
      "Collecting opentelemetry-proto==1.34.1 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb)\n",
      "  Using cached opentelemetry_proto-1.34.1-py3-none-any.whl.metadata (2.4 kB)\n",
      "Collecting protobuf (from onnxruntime>=1.14.1->chromadb)\n",
      "  Using cached protobuf-5.29.5-cp310-abi3-win_amd64.whl.metadata (592 bytes)\n",
      "Collecting opentelemetry-semantic-conventions==0.55b1 (from opentelemetry-sdk>=1.2.0->chromadb)\n",
      "  Using cached opentelemetry_semantic_conventions-0.55b1-py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting backoff>=1.10.0 (from posthog<6.0.0,>=2.4.0->chromadb)\n",
      "  Using cached backoff-2.2.1-py3-none-any.whl.metadata (14 kB)\n",
      "Collecting annotated-types>=0.6.0 (from pydantic<3,>=1.9.0->openai)\n",
      "  Using cached annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting pydantic-core==2.33.2 (from pydantic<3,>=1.9.0->openai)\n",
      "  Using cached pydantic_core-2.33.2-cp312-cp312-win_amd64.whl.metadata (6.9 kB)\n",
      "Collecting typing-inspection>=0.4.0 (from pydantic<3,>=1.9.0->openai)\n",
      "  Using cached typing_inspection-0.4.1-py3-none-any.whl.metadata (2.6 kB)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\misogi\\week5\\day1\\rag_evaluation\\intent_classifier\\myenv\\lib\\site-packages (from requests->transformers) (3.4.2)\n",
      "Collecting markdown-it-py>=2.2.0 (from rich>=10.11.0->chromadb)\n",
      "  Using cached markdown_it_py-3.0.0-py3-none-any.whl.metadata (6.9 kB)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\misogi\\week5\\day1\\rag_evaluation\\intent_classifier\\myenv\\lib\\site-packages (from rich>=10.11.0->chromadb) (2.19.2)\n",
      "Collecting networkx (from torch>=1.11.0->sentence-transformers)\n",
      "  Using cached networkx-3.5-py3-none-any.whl.metadata (6.3 kB)\n",
      "Requirement already satisfied: jinja2 in c:\\misogi\\week5\\day1\\rag_evaluation\\intent_classifier\\myenv\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (3.1.6)\n",
      "Requirement already satisfied: setuptools in c:\\misogi\\week5\\day1\\rag_evaluation\\intent_classifier\\myenv\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (80.9.0)\n",
      "Collecting shellingham>=1.3.0 (from typer>=0.9.0->chromadb)\n",
      "  Using cached shellingham-1.5.4-py2.py3-none-any.whl.metadata (3.5 kB)\n",
      "Collecting httptools>=0.6.3 (from uvicorn[standard]>=0.18.3->chromadb)\n",
      "  Using cached httptools-0.6.4-cp312-cp312-win_amd64.whl.metadata (3.7 kB)\n",
      "Collecting python-dotenv>=0.13 (from uvicorn[standard]>=0.18.3->chromadb)\n",
      "  Using cached python_dotenv-1.1.1-py3-none-any.whl.metadata (24 kB)\n",
      "Collecting watchfiles>=0.13 (from uvicorn[standard]>=0.18.3->chromadb)\n",
      "  Using cached watchfiles-1.1.0-cp312-cp312-win_amd64.whl.metadata (5.0 kB)\n",
      "Collecting websockets>=10.4 (from uvicorn[standard]>=0.18.3->chromadb)\n",
      "  Using cached websockets-15.0.1-cp312-cp312-win_amd64.whl.metadata (7.0 kB)\n",
      "Collecting joblib>=1.2.0 (from scikit-learn->sentence-transformers)\n",
      "  Using cached joblib-1.5.1-py3-none-any.whl.metadata (5.6 kB)\n",
      "Collecting threadpoolctl>=3.1.0 (from scikit-learn->sentence-transformers)\n",
      "  Using cached threadpoolctl-3.6.0-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting cachetools<6.0,>=2.0.0 (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb)\n",
      "  Using cached cachetools-5.5.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting pyasn1-modules>=0.2.1 (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb)\n",
      "  Using cached pyasn1_modules-0.4.2-py3-none-any.whl.metadata (3.5 kB)\n",
      "Collecting rsa<5,>=3.1.4 (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb)\n",
      "  Using cached rsa-4.9.1-py3-none-any.whl.metadata (5.6 kB)\n",
      "Collecting zipp>=3.20 (from importlib-metadata<8.8.0,>=6.0->opentelemetry-api>=1.2.0->chromadb)\n",
      "  Using cached zipp-3.23.0-py3-none-any.whl.metadata (3.6 kB)\n",
      "Collecting mdurl~=0.1 (from markdown-it-py>=2.2.0->rich>=10.11.0->chromadb)\n",
      "  Using cached mdurl-0.1.2-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting mpmath<1.4,>=1.1.0 (from sympy->onnxruntime>=1.14.1->chromadb)\n",
      "  Using cached mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\n",
      "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime>=1.14.1->chromadb)\n",
      "  Using cached humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\misogi\\week5\\day1\\rag_evaluation\\intent_classifier\\myenv\\lib\\site-packages (from jinja2->torch>=1.11.0->sentence-transformers) (3.0.2)\n",
      "Collecting pyreadline3 (from humanfriendly>=9.1->coloredlogs->onnxruntime>=1.14.1->chromadb)\n",
      "  Using cached pyreadline3-3.5.4-py3-none-any.whl.metadata (4.7 kB)\n",
      "Collecting pyasn1<0.7.0,>=0.6.1 (from pyasn1-modules>=0.2.1->google-auth>=1.0.1->kubernetes>=28.1.0->chromadb)\n",
      "  Using cached pyasn1-0.6.1-py3-none-any.whl.metadata (8.4 kB)\n",
      "Using cached transformers-4.53.1-py3-none-any.whl (10.8 MB)\n",
      "Using cached sentence_transformers-5.0.0-py3-none-any.whl (470 kB)\n",
      "Using cached openai-1.93.1-py3-none-any.whl (755 kB)\n",
      "Using cached chromadb-1.0.15-cp39-abi3-win_amd64.whl (19.5 MB)\n",
      "Downloading fastapi-0.116.0-py3-none-any.whl (95 kB)\n",
      "Using cached uvicorn-0.35.0-py3-none-any.whl (66 kB)\n",
      "Using cached bcrypt-4.3.0-cp39-abi3-win_amd64.whl (152 kB)\n",
      "Using cached build-1.2.2.post1-py3-none-any.whl (22 kB)\n",
      "Using cached click-8.2.1-py3-none-any.whl (102 kB)\n",
      "Using cached distro-1.9.0-py3-none-any.whl (20 kB)\n",
      "Using cached grpcio-1.73.1-cp312-cp312-win_amd64.whl (4.3 MB)\n",
      "Using cached huggingface_hub-0.33.2-py3-none-any.whl (515 kB)\n",
      "Using cached jiter-0.10.0-cp312-cp312-win_amd64.whl (206 kB)\n",
      "Using cached kubernetes-33.1.0-py2.py3-none-any.whl (1.9 MB)\n",
      "Using cached mmh3-5.1.0-cp312-cp312-win_amd64.whl (41 kB)\n",
      "Using cached numpy-2.3.1-cp312-cp312-win_amd64.whl (12.7 MB)\n",
      "Using cached onnxruntime-1.22.0-cp312-cp312-win_amd64.whl (12.7 MB)\n",
      "Using cached opentelemetry_api-1.34.1-py3-none-any.whl (65 kB)\n",
      "Using cached opentelemetry_exporter_otlp_proto_grpc-1.34.1-py3-none-any.whl (18 kB)\n",
      "Using cached opentelemetry_exporter_otlp_proto_common-1.34.1-py3-none-any.whl (18 kB)\n",
      "Using cached opentelemetry_proto-1.34.1-py3-none-any.whl (55 kB)\n",
      "Using cached opentelemetry_sdk-1.34.1-py3-none-any.whl (118 kB)\n",
      "Using cached opentelemetry_semantic_conventions-0.55b1-py3-none-any.whl (196 kB)\n",
      "Using cached orjson-3.10.18-cp312-cp312-win_amd64.whl (134 kB)\n",
      "Using cached posthog-5.4.0-py3-none-any.whl (105 kB)\n",
      "Using cached pybase64-1.4.1-cp312-cp312-win_amd64.whl (36 kB)\n",
      "Using cached pydantic-2.11.7-py3-none-any.whl (444 kB)\n",
      "Using cached pydantic_core-2.33.2-cp312-cp312-win_amd64.whl (2.0 MB)\n",
      "Using cached regex-2024.11.6-cp312-cp312-win_amd64.whl (273 kB)\n",
      "Using cached rich-14.0.0-py3-none-any.whl (243 kB)\n",
      "Using cached safetensors-0.5.3-cp38-abi3-win_amd64.whl (308 kB)\n",
      "Using cached starlette-0.46.2-py3-none-any.whl (72 kB)\n",
      "Using cached tenacity-9.1.2-py3-none-any.whl (28 kB)\n",
      "Using cached tokenizers-0.21.2-cp39-abi3-win_amd64.whl (2.5 MB)\n",
      "Using cached torch-2.7.1-cp312-cp312-win_amd64.whl (216.1 MB)\n",
      "Using cached tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "Using cached typer-0.16.0-py3-none-any.whl (46 kB)\n",
      "Using cached filelock-3.18.0-py3-none-any.whl (16 kB)\n",
      "Using cached importlib_resources-6.5.2-py3-none-any.whl (37 kB)\n",
      "Using cached pillow-11.3.0-cp312-cp312-win_amd64.whl (7.0 MB)\n",
      "Using cached scikit_learn-1.7.0-cp312-cp312-win_amd64.whl (10.7 MB)\n",
      "Using cached scipy-1.16.0-cp312-cp312-win_amd64.whl (38.4 MB)\n",
      "Using cached annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
      "Using cached backoff-2.2.1-py3-none-any.whl (15 kB)\n",
      "Using cached durationpy-0.10-py3-none-any.whl (3.9 kB)\n",
      "Using cached fsspec-2025.5.1-py3-none-any.whl (199 kB)\n",
      "Using cached google_auth-2.40.3-py2.py3-none-any.whl (216 kB)\n",
      "Using cached googleapis_common_protos-1.70.0-py3-none-any.whl (294 kB)\n",
      "Using cached httptools-0.6.4-cp312-cp312-win_amd64.whl (88 kB)\n",
      "Using cached importlib_metadata-8.7.0-py3-none-any.whl (27 kB)\n",
      "Using cached joblib-1.5.1-py3-none-any.whl (307 kB)\n",
      "Using cached markdown_it_py-3.0.0-py3-none-any.whl (87 kB)\n",
      "Using cached oauthlib-3.3.1-py3-none-any.whl (160 kB)\n",
      "Using cached protobuf-5.29.5-cp310-abi3-win_amd64.whl (434 kB)\n",
      "Using cached python_dotenv-1.1.1-py3-none-any.whl (20 kB)\n",
      "Using cached shellingham-1.5.4-py2.py3-none-any.whl (9.8 kB)\n",
      "Using cached sympy-1.14.0-py3-none-any.whl (6.3 MB)\n",
      "Using cached threadpoolctl-3.6.0-py3-none-any.whl (18 kB)\n",
      "Using cached typing_inspection-0.4.1-py3-none-any.whl (14 kB)\n",
      "Using cached watchfiles-1.1.0-cp312-cp312-win_amd64.whl (292 kB)\n",
      "Using cached websockets-15.0.1-cp312-cp312-win_amd64.whl (176 kB)\n",
      "Using cached coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
      "Using cached flatbuffers-25.2.10-py2.py3-none-any.whl (30 kB)\n",
      "Using cached networkx-3.5-py3-none-any.whl (2.0 MB)\n",
      "Using cached pyproject_hooks-1.2.0-py3-none-any.whl (10 kB)\n",
      "Using cached requests_oauthlib-2.0.0-py2.py3-none-any.whl (24 kB)\n",
      "Using cached cachetools-5.5.2-py3-none-any.whl (10 kB)\n",
      "Using cached humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
      "Using cached mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
      "Using cached mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "Using cached pyasn1_modules-0.4.2-py3-none-any.whl (181 kB)\n",
      "Using cached rsa-4.9.1-py3-none-any.whl (34 kB)\n",
      "Using cached zipp-3.23.0-py3-none-any.whl (10 kB)\n",
      "Using cached pyasn1-0.6.1-py3-none-any.whl (83 kB)\n",
      "Using cached pyreadline3-3.5.4-py3-none-any.whl (83 kB)\n",
      "Installing collected packages: pypika, mpmath, flatbuffers, durationpy, zipp, websockets, typing-inspection, tqdm, threadpoolctl, tenacity, sympy, shellingham, safetensors, regex, python-dotenv, pyreadline3, pyproject_hooks, pydantic-core, pybase64, pyasn1, protobuf, Pillow, orjson, oauthlib, numpy, networkx, mmh3, mdurl, joblib, jiter, importlib-resources, httptools, grpcio, fsspec, filelock, distro, click, cachetools, bcrypt, backoff, annotated-types, watchfiles, uvicorn, torch, starlette, scipy, rsa, requests-oauthlib, pydantic, pyasn1-modules, posthog, opentelemetry-proto, markdown-it-py, importlib-metadata, humanfriendly, huggingface-hub, googleapis-common-protos, build, tokenizers, scikit-learn, rich, opentelemetry-exporter-otlp-proto-common, opentelemetry-api, openai, google-auth, fastapi, coloredlogs, typer, transformers, opentelemetry-semantic-conventions, onnxruntime, kubernetes, sentence-transformers, opentelemetry-sdk, opentelemetry-exporter-otlp-proto-grpc, chromadb\n",
      "Successfully installed Pillow-11.3.0 annotated-types-0.7.0 backoff-2.2.1 bcrypt-4.3.0 build-1.2.2.post1 cachetools-5.5.2 chromadb-1.0.15 click-8.2.1 coloredlogs-15.0.1 distro-1.9.0 durationpy-0.10 fastapi-0.116.0 filelock-3.18.0 flatbuffers-25.2.10 fsspec-2025.5.1 google-auth-2.40.3 googleapis-common-protos-1.70.0 grpcio-1.73.1 httptools-0.6.4 huggingface-hub-0.33.2 humanfriendly-10.0 importlib-metadata-8.7.0 importlib-resources-6.5.2 jiter-0.10.0 joblib-1.5.1 kubernetes-33.1.0 markdown-it-py-3.0.0 mdurl-0.1.2 mmh3-5.1.0 mpmath-1.3.0 networkx-3.5 numpy-2.3.1 oauthlib-3.3.1 onnxruntime-1.22.0 openai-1.93.1 opentelemetry-api-1.34.1 opentelemetry-exporter-otlp-proto-common-1.34.1 opentelemetry-exporter-otlp-proto-grpc-1.34.1 opentelemetry-proto-1.34.1 opentelemetry-sdk-1.34.1 opentelemetry-semantic-conventions-0.55b1 orjson-3.10.18 posthog-5.4.0 protobuf-5.29.5 pyasn1-0.6.1 pyasn1-modules-0.4.2 pybase64-1.4.1 pydantic-2.11.7 pydantic-core-2.33.2 pypika-0.48.9 pyproject_hooks-1.2.0 pyreadline3-3.5.4 python-dotenv-1.1.1 regex-2024.11.6 requests-oauthlib-2.0.0 rich-14.0.0 rsa-4.9.1 safetensors-0.5.3 scikit-learn-1.7.0 scipy-1.16.0 sentence-transformers-5.0.0 shellingham-1.5.4 starlette-0.46.2 sympy-1.14.0 tenacity-9.1.2 threadpoolctl-3.6.0 tokenizers-0.21.2 torch-2.7.1 tqdm-4.67.1 transformers-4.53.1 typer-0.16.0 typing-inspection-0.4.1 uvicorn-0.35.0 watchfiles-1.1.0 websockets-15.0.1 zipp-3.23.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.0.1 -> 25.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers sentence-transformers openai chromadb fastapi uvicorn nest-asyncio\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "10d28e3a-b17c-4b59-b192-10d6ba84fad7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Misogi\\Week5\\DAY1\\RAG_Evaluation\\Intent_Classifier\\myenv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "C:\\Misogi\\Week5\\DAY1\\RAG_Evaluation\\Intent_Classifier\\myenv\\Lib\\site-packages\\huggingface_hub\\file_download.py:143: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\harsh\\.cache\\huggingface\\hub\\models--bhadresh-savani--distilbert-base-uncased-emotion. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n",
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
      "Device set to use cpu\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "# Load a general-purpose emotion classifier (can be fine-tuned later)\n",
    "intent_classifier = pipeline(\"text-classification\", model=\"bhadresh-savani/distilbert-base-uncased-emotion\")\n",
    "\n",
    "# Intent Mapping\n",
    "def map_intent(label):\n",
    "    if label in [\"joy\", \"love\"]:\n",
    "        return \"Feature Request\"\n",
    "    elif label in [\"anger\", \"fear\", \"sadness\"]:\n",
    "        return \"Billing\"\n",
    "    else:\n",
    "        return \"Technical Support\"\n",
    "\n",
    "def detect_intent(query):\n",
    "    label = intent_classifier(query)[0][\"label\"]\n",
    "    return map_intent(label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "806db4ce-7348-409a-910b-a0bdb9e240de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: python-dotenv in c:\\misogi\\week5\\day1\\rag_evaluation\\intent_classifier\\myenv\\lib\\site-packages (1.1.1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.0.1 -> 25.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3484331f-6f52-4173-b8a5-4c01c8e93c58",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import openai\n",
    "import time\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "load_dotenv()\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "class LLMRouter:\n",
    "    def __init__(self, use_openai=False):\n",
    "        self.use_openai = use_openai\n",
    "\n",
    "    def query(self, prompt):\n",
    "        try:\n",
    "            if self.use_openai:\n",
    "                start = time.time()\n",
    "                response = openai.ChatCompletion.create(\n",
    "                    model=\"gpt-4\",\n",
    "                    messages=[{\"role\": \"user\", \"content\": prompt}]\n",
    "                )\n",
    "                latency = time.time() - start\n",
    "                return response.choices[0].message.content.strip(), latency\n",
    "            else:\n",
    "                start = time.time()\n",
    "                res = requests.post(\"http://localhost:11434/api/generate\", json={\n",
    "                    \"model\": \"llama3\",\n",
    "                    \"prompt\": prompt,\n",
    "                    \"stream\": False\n",
    "                })\n",
    "                latency = time.time() - start\n",
    "                return res.json()['response'], latency\n",
    "        except Exception:\n",
    "            self.use_openai = True\n",
    "            return self.query(prompt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "24583ef6-a8a9-416e-97df-932b655e2fc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulate sample retrieval context for each intent\n",
    "def retrieve_context(intent):\n",
    "    if intent == \"Technical Support\":\n",
    "        return \"To reset your password, go to settings > security > reset password.\"\n",
    "    elif intent == \"Billing\":\n",
    "        return \"Our pricing tiers include Basic, Pro, and Enterprise. Missed payments result in account hold.\"\n",
    "    elif intent == \"Feature Request\":\n",
    "        return \"We are planning 2FA support in Q3 and AI summarization in Q4 per roadmap.\"\n",
    "\n",
    "# Prompt template builder\n",
    "def build_prompt(intent, query, context):\n",
    "    if intent == \"Technical Support\":\n",
    "        return f\"Using the following documentation:\\n{context}\\n\\nAnswer this tech support query:\\n{query}\"\n",
    "    elif intent == \"Billing\":\n",
    "        return f\"Based on billing policies:\\n{context}\\n\\nAnswer the customer question:\\n{query}\"\n",
    "    elif intent == \"Feature Request\":\n",
    "        return f\"Based on our product roadmap:\\n{context}\\n\\nAddress this feature request:\\n{query}\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a4f1d4ed-e94d-4430-90a3-fec2d5059670",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer, util\n",
    "\n",
    "embedder = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "\n",
    "# Cosine similarity with ideal response\n",
    "def relevance_score(response, ideal):\n",
    "    return float(util.cos_sim(embedder.encode(response), embedder.encode(ideal))[0][0])\n",
    "\n",
    "# Overlap-based context utilization\n",
    "def context_utilization_score(response, context):\n",
    "    context_words = set(context.lower().split())\n",
    "    response_words = set(response.lower().split())\n",
    "    return len(context_words & response_words) / len(context_words)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "25cdf41c-bf1f-4846-9d9e-ab0f1d008173",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intent Detected: Feature Request\n",
      "LLM Response: I'm happy to help! Based on our current product roadmap, we're planning to implement two-factor authentication (2FA) in Q3. This means that 2FA support is already slated for development and will be available in the coming quarter.\n",
      "\n",
      "Since this feature is already planned, I won't be able to add it to our roadmap at this time. However, if you'd like to provide any specific requirements or feedback on how you envision 2FA working in our product, I'm more than happy to take that into consideration and pass it along to the development team.\n",
      "\n",
      "If there's anything else I can help with, please don't hesitate to ask!\n",
      "\n",
      "ðŸ“Š Evaluation Metrics\n",
      "Relevance Score: 0.809\n",
      "Context Utilization: 0.385\n",
      "Latency (sec): 26.51\n"
     ]
    }
   ],
   "source": [
    "# Setup\n",
    "llm = LLMRouter(use_openai=False)\n",
    "\n",
    "# Sample Query\n",
    "query = \"Can you add support for two-factor authentication?\"\n",
    "ideal_answer = \"Two-factor authentication is a planned feature for Q3 as per our roadmap.\"\n",
    "\n",
    "# 1. Intent detection\n",
    "intent = detect_intent(query)\n",
    "print(\"Intent Detected:\", intent)\n",
    "\n",
    "# 2. Retrieve context and build prompt\n",
    "context = retrieve_context(intent)\n",
    "prompt = build_prompt(intent, query, context)\n",
    "\n",
    "# 3. Generate response\n",
    "response, latency = llm.query(prompt)\n",
    "print(\"LLM Response:\", response)\n",
    "\n",
    "# 4. Evaluation\n",
    "relevance = relevance_score(response, ideal_answer)\n",
    "context_util = context_utilization_score(response, context)\n",
    "\n",
    "print(\"\\nðŸ“Š Evaluation Metrics\")\n",
    "print(\"Relevance Score:\", round(relevance, 3))\n",
    "print(\"Context Utilization:\", round(context_util, 3))\n",
    "print(\"Latency (sec):\", round(latency, 2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f63002b6-3d84-4550-9293-597d8729fc27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pandas\n",
      "  Using cached pandas-2.3.1-cp312-cp312-win_amd64.whl.metadata (19 kB)\n",
      "Requirement already satisfied: numpy>=1.26.0 in c:\\misogi\\week5\\day1\\rag_evaluation\\intent_classifier\\myenv\\lib\\site-packages (from pandas) (2.3.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\misogi\\week5\\day1\\rag_evaluation\\intent_classifier\\myenv\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Collecting pytz>=2020.1 (from pandas)\n",
      "  Using cached pytz-2025.2-py2.py3-none-any.whl.metadata (22 kB)\n",
      "Collecting tzdata>=2022.7 (from pandas)\n",
      "  Using cached tzdata-2025.2-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Requirement already satisfied: six>=1.5 in c:\\misogi\\week5\\day1\\rag_evaluation\\intent_classifier\\myenv\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Using cached pandas-2.3.1-cp312-cp312-win_amd64.whl (11.0 MB)\n",
      "Using cached pytz-2025.2-py2.py3-none-any.whl (509 kB)\n",
      "Using cached tzdata-2025.2-py2.py3-none-any.whl (347 kB)\n",
      "Installing collected packages: pytz, tzdata, pandas\n",
      "Successfully installed pandas-2.3.1 pytz-2025.2 tzdata-2025.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.0.1 -> 25.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "775cb31f-2286-4f40-bb46-3874c57cd5b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Query</th>\n",
       "      <th>True Intent</th>\n",
       "      <th>Predicted Intent</th>\n",
       "      <th>Response</th>\n",
       "      <th>Relevance</th>\n",
       "      <th>Context Utilization</th>\n",
       "      <th>Latency</th>\n",
       "      <th>Intent Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>How do I reset my password?</td>\n",
       "      <td>Technical Support</td>\n",
       "      <td>Billing</td>\n",
       "      <td>To reset your password, please follow these st...</td>\n",
       "      <td>0.667510</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>26.213994</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What happens if I miss a payment?</td>\n",
       "      <td>Billing</td>\n",
       "      <td>Billing</td>\n",
       "      <td>According to our billing policies, if you miss...</td>\n",
       "      <td>0.676389</td>\n",
       "      <td>0.214286</td>\n",
       "      <td>5.884278</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Can you add AI-based tagging?</td>\n",
       "      <td>Feature Request</td>\n",
       "      <td>Feature Request</td>\n",
       "      <td>Thank you for the context! Based on our produc...</td>\n",
       "      <td>0.711357</td>\n",
       "      <td>0.461538</td>\n",
       "      <td>32.393183</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               Query        True Intent Predicted Intent  \\\n",
       "0        How do I reset my password?  Technical Support          Billing   \n",
       "1  What happens if I miss a payment?            Billing          Billing   \n",
       "2      Can you add AI-based tagging?    Feature Request  Feature Request   \n",
       "\n",
       "                                            Response  Relevance  \\\n",
       "0  To reset your password, please follow these st...   0.667510   \n",
       "1  According to our billing policies, if you miss...   0.676389   \n",
       "2  Thank you for the context! Based on our produc...   0.711357   \n",
       "\n",
       "   Context Utilization    Latency  Intent Accuracy  \n",
       "0             0.285714  26.213994            False  \n",
       "1             0.214286   5.884278             True  \n",
       "2             0.461538  32.393183             True  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Simulated test set\n",
    "data = [\n",
    "    (\"How do I reset my password?\", \"Technical Support\", \"You can reset your password from settings.\"),\n",
    "    (\"What happens if I miss a payment?\", \"Billing\", \"Missed payments result in a temporary account hold.\"),\n",
    "    (\"Can you add AI-based tagging?\", \"Feature Request\", \"AI-based tagging is being explored for future releases.\")\n",
    "]\n",
    "\n",
    "results = []\n",
    "\n",
    "for query, true_intent, ideal_answer in data:\n",
    "    pred_intent = detect_intent(query)\n",
    "    context = retrieve_context(pred_intent)\n",
    "    prompt = build_prompt(pred_intent, query, context)\n",
    "    response, latency = llm.query(prompt)\n",
    "\n",
    "    results.append({\n",
    "        \"Query\": query,\n",
    "        \"True Intent\": true_intent,\n",
    "        \"Predicted Intent\": pred_intent,\n",
    "        \"Response\": response,\n",
    "        \"Relevance\": relevance_score(response, ideal_answer),\n",
    "        \"Context Utilization\": context_utilization_score(response, context),\n",
    "        \"Latency\": latency\n",
    "    })\n",
    "\n",
    "df = pd.DataFrame(results)\n",
    "df[\"Intent Accuracy\"] = df[\"True Intent\"] == df[\"Predicted Intent\"]\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8945e820-9402-47a9-9ed6-d7ce02819a17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Intent Accuracy: 0.6666666666666666\n",
      "âœ… Avg Relevance: 0.6850851774215698\n",
      "âœ… Avg Context Utilization: 0.32051282051282054\n",
      "âœ… Avg Latency: 21.497151533762615\n"
     ]
    }
   ],
   "source": [
    "print(\"âœ… Intent Accuracy:\", df[\"Intent Accuracy\"].mean())\n",
    "print(\"âœ… Avg Relevance:\", df[\"Relevance\"].mean())\n",
    "print(\"âœ… Avg Context Utilization:\", df[\"Context Utilization\"].mean())\n",
    "print(\"âœ… Avg Latency:\", df[\"Latency\"].mean())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aca12e8-81ff-41fa-8ddc-ec414e75ee7f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
